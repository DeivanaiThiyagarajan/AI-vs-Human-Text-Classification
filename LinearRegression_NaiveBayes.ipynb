{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01452c77-4410-4e9b-8dc1-2f67d5cba7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle to save the model and processed data\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd51339f-1b5d-4461-8bf3-5729ea4cf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DataSets/Processed_Data_small.csv',delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4861d68-90e1-477b-824d-03e7af3e8d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 399852 entries, 0 to 399999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   generated           399852 non-null  float64\n",
      " 1   text                399852 non-null  object \n",
      " 2   avg_len_sentences   399852 non-null  float64\n",
      " 3   words_count         399852 non-null  int64  \n",
      " 4   punctuations_count  399852 non-null  int64  \n",
      " 5   readability_score   399852 non-null  float64\n",
      " 6   stop_word_ratio     399852 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace = True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd54e00-6fa6-46a7-ad94-a6a7e3f1174f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'null_rows = data.isnull().sum(axis=1)\\n\\n# Filter for rows with at least one null value\\nrows_with_nulls = data[null_rows > 0]\\n\\nrows_with_nulls.info()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''null_rows = data.isnull().sum(axis=1)\n",
    "\n",
    "# Filter for rows with at least one null value\n",
    "rows_with_nulls = data[null_rows > 0]\n",
    "\n",
    "rows_with_nulls.info()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427eb8ac-b6de-4edc-aa6e-4a554e279c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['text','avg_len_sentences','punctuations_count','words_count','stop_word_ratio','readability_score']]\n",
    "y=data['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2676d5a-a40c-480f-8079-6446b08b5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d22e32-d267-41dc-873c-97d1c5f5df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1, 3))),  # Step 1: CountVectorizer\n",
    "    ('tfidf_transformer', TfidfTransformer( ))  # Step 2: TF-IDF Transformation\n",
    "])\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler())  # Scale numerical features\n",
    "])\n",
    "\n",
    "# Combine text and numerical pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('text', text_pipeline, 'text'),  # Apply text pipeline to 'text' column\n",
    "    ('numerical', numerical_pipeline, ['avg_len_sentences', 'punctuations_count','readability_score','words_count','stop_word_ratio'])  # Apply numerical pipeline\n",
    "])\n",
    "\n",
    "# Final pipeline with preprocessor and model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', MultinomialNB())  # Replace with any model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2f83b-0f90-4a2f-a053-237e69885d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739431e-f7f4-44fa-bc5d-efe1e970812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0354f-42f5-4914-be75-1c0f1538b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e93ef0-981b-4d3e-9508-395fceefd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NaiveBayesClassifier.pkl', 'wb') as file:\n",
    "    pkl.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b7ec9-52bc-453a-8711-b5e4c41fc208",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())  # Replace with any model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8034c69-f296-4822-9da7-02c488326ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5361a0-4343-4840-8704-157ebe488cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= pipeline2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c170c-520d-47d0-ba43-b4340db89576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03317f7c-fca3-48cb-8c10-e8fd146e1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LogisticRegressionClassifier2.pkl', 'wb') as file:\n",
    "    pkl.dump(pipeline2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c2cf0-ab44-4105-8d7d-29544f003dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
